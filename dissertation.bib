@article{3d_conv, 
    title={3D convolutional neural network for object recognition: a review}, 
    volume={78}, DOI={10.1007/s11042-018-6912-6}, number={12}, 
    journal={Multimedia Tools and Applications}, 
    author={Singh, Rahul Dev and Mittal, Ajay and Bhatia, Rajesh K.}, 
    year={2018}, 
    month={Nov}, 
    pages={15951–15995}
}

@article{activation_search,
  title={Searching for activation functions},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.05941},
  year={2017}
}

@misc{ai_slides,
  author        = {Jo{\~a}o Cunha},
  title         = {Lecture notes in Computer Assisted Diagnosis},
  month         = {February},
  year          = {2013},
  publisher={Faculdade de Engenharia da Universidade do Porto}
}

@article{ai_winter,
  title={Avoiding another AI winter},
  author={Hendler, James},
  journal={IEEE Intelligent Systems},
  number={2},
  pages={2--4},
  year={2008},
  publisher={IEEE}
}

@Online{ai_winter_spec,
 author = {Shead, Sam},
 year = {2020},
 title = {Researchers: Are we on the cusp of an 'AI winter'?},
 journal = {British Broadcasting Corporation News},
 url = {https://www.bbc.com/news/technology-51064369},
 urldate = {2020-01-12}
}

@inproceedings{alexnet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@article{alphago,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{alphastar,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{are_loss_functions,
author = {Rosasco, Lorenzo and De Vito, Ernesto and Caponnetto, Andrea and Piana, Michele and Verri, Alessandro},
title = {Are Loss Functions All the Same?},
year = {2004},
issue_date = {May 2004},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {16},
number = {5},
issn = {0899-7667},
url = {https://doi.org/10.1162/089976604773135104},
doi = {10.1162/089976604773135104},
journal = {Neural Comput.},
month = may,
pages = {1063–1076},
numpages = {14}
}

@phdthesis{bob_learning_high_dim,
  title={Learning in high dimensions with projected linear discriminants},
  author={Durrant, Robert John},
  year={2013},
  school={University of Birmingham}
}

@misc{bob_rp_storage,
  author       = {Dr Robert Durrant},
  howpublished = {{Private Communication}},
  year         = {2019},
  month        = {November},
  address      = {The University of Waikato, Hamilton, New Zealand},
  comment      = {We discussed the storage of random projection matrices. Dr Durrant explained that this introduces weak dependencies into the training of the network, but that in practice this is unlikely to make a difference.},
  institution  = {The University of Waikato},
}

@inproceedings{bob_sharp_generalisation_error_bounds,
  title={Sharp generalization error bounds for randomly-projected classifiers},
  author={Durrant, Robert and Kab{\'a}n, Ata},
  booktitle={International Conference on Machine Learning},
  pages={693--701},
  year={2013}
}

@article{dartmouth_summer,
  title={A proposal for the dartmouth summer research project on artificial intelligence, august 31, 1955},
  author={McCarthy, John and Minsky, Marvin L and Rochester, Nathaniel and Shannon, Claude E},
  journal={AI magazine},
  volume={27},
  number={4},
  pages={12--12},
  year={2006}
}

@article{deep_forest,
  title={Deep forest},
  author={Zhou, Zhi-Hua and Feng, Ji},
  journal={arXiv preprint arXiv:1702.08835},
  year={2017}
}

@article{dl_overview,
  title={Deep learning in neural networks: An overview},
  author={Schmidhuber, J{\"u}rgen},
  journal={Neural networks},
  volume={61},
  pages={85--117},
  year={2015},
  publisher={Elsevier}
}

@inproceedings{durrant2013sharp,
  title={Sharp generalization error bounds for randomly-projected classifiers},
  author={Durrant, Robert and Kab{\'a}n, Ata},
  booktitle={International Conference on Machine Learning},
  pages={693--701},
  year={2013}
}

@inproceedings{gans,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}

@book{good_fellow_2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@inbook{haykin,
  title={Single Layer Perceptrons},
  booktitle={Neural Networks: A Comprehensive Foundation},
  author={Haykin, Simon},
  year={1998},
  chapter={3},
  pages={117-151},
  publisher={Prentice Hall Internation, Inc}
}

@article{hopfieldnetworks,
  title={Neural networks and physical systems with emergent collective computational abilities},
  author={Hopfield, John J},
  journal={Proceedings of the national academy of sciences},
  volume={79},
  number={8},
  pages={2554--2558},
  year={1982},
  publisher={National Acad Sciences}
}

@misc{jll_notes,
  author        = {Mahony, Michael},
  title         = {The Johnson-Lindenstrauss Lemma},
  institution   = {Stanford University},
  series        = {CS369M: Algorithms for Modern Massive Data Set Analysis},
  type          = {Lecture Notes},
  month         = {September},
  year          = {2009},
  publisher={Stanford University}
}

@misc{keras_r, 
    title={R Interface to 'Keras'}, 
    url={https://keras.rstudio.com/}
}

@inproceedings{k_means,
  title={Some methods for classification and analysis of multivariate observations},
  author={MacQueen, James and others},
  booktitle={Proceedings of the fifth Berkeley symposium on mathematical statistics and probability},
  volume={1},
  number={14},
  pages={281--297},
  year={1967},
  organization={Oakland, CA, USA}
}

@inproceedings{label_noise,
  title={Label-noise robust logistic regression and its applications},
  author={Bootkrajang, Jakramate and Kab{\'a}n, Ata},
  booktitle={Joint European conference on machine learning and knowledge discovery in databases},
  pages={143--158},
  year={2012},
  organization={Springer}
}

@article{LeNet,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@article{logical_calculus,
  title={A logical calculus of the ideas immanent in nervous activity},
  author={McCulloch, Warren S and Pitts, Walter},
  journal={The bulletin of mathematical biophysics},
  volume={5},
  number={4},
  pages={115--133},
  year={1943},
  publisher={Springer}
}

@inproceedings{loss_landscape,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6389--6399},
  year={2018}
}

@article{ltsm,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@article{moves_chess_go,
  title={Chess, Shogi, Go, natural developments in game research},
  author={Matsubara, Hitoshi and Iida, Hiroyuki and Grimbergen, Reijer}
}

@article{mnist,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}

@article{mnist_results,
  title={Assessing four neural networks on handwritten digit recognition data set (MNIST)},
  author={Chen, Feiyang and Chen, Nan and Mao, Hanyang and Hu, Hanlin},
  journal={arXiv preprint arXiv:1811.08278},
  year={2018}
}

@misc{mnist_script,
  title = {MNIST Handwritten Digit Recognition in PyTorch},
  author = {Koehler, Greg},
  howpublished = {\url{http://web.archive.org/web/20200223040606/https://nextjournal.com/gkoehler/pytorch-mnist}},
  note = {Accessed: 2020-03-23}
}

@misc{mnist_sota,
    title={A Branching and Merging Convolutional Network with Homogeneous Filter Capsules},
    author={Adam Byerly and Tatiana Kalganova and Ian Dear},
    year={2020},
    eprint={2001.09136},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{mnist_sota_web, 
    title={MNIST Leaderboard: Papers with Code}, url={https://paperswithcode.com/sota/image-classification-on-mnist}, journal={Papers With Code : the latest in machine learning}, publisher={Atlas ML}, 
    author={Stojnic, Robert and Taylor, Ross}
}

@inproceedings{mnist_viz,
    title = {An Interactive Node-Link Visualization of Convolutional Neural Networks},
    author = {Adam W Harley},
    booktitle = {ISVC},
    pages = {867--877},
    year = {2015}
}

@article{neocognitron,
  title={Neocognitron: A hierarchical neural network capable of visual pattern recognition},
  author={Fukushima, Kunihiko},
  journal={Neural networks},
  volume={1},
  number={2},
  pages={119--130},
  year={1988},
  publisher={Elsevier}
}

@article{neocognitron_proposal,
  title={Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
  author={Fukushima, Kunihiko},
  journal={Biological cybernetics},
  volume={36},
  number={4},
  pages={193--202},
  year={1980},
  publisher={Springer}
}

@misc{nist,
  doi = {10.18434/T4H01C},
  url = {http://www.nist.gov/srd/nistsd19.cfm},
  author = {Grother,  Patrick J. and Flanagan,  Patricia A.},
  language = {eng},
  title = {NIST Handprinted Forms and Characters,  NIST  Special Database 19.},
  publisher = {National Institute of Standards and Technology},
  year = {1995}
}

@article{nn_interpretability,
  title={On Interpretability of Artificial Neural Networks},
  author={Fan, Fenglei and Xiong, Jinjun and Wang, Ge},
  journal={arXiv preprint arXiv:2001.02522},
  year={2020}
}

@article{perceptron_paper,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Rosenblatt, Frank},
  journal={Psychological review},
  volume={65},
  number={6},
  pages={386},
  year={1958},
  publisher={American Psychological Association}
}

@article{press_alpha_go,
  title={One giant step for a chess-playing machine},
  author={Strogatz, Steven},
  journal={New York Times},
  year={2018}
}

@article{press_alpha_star, 
    title={DeepMind AI achieves Grandmaster status at Starcraft 2}, 
    url={DeepMind AI achieves Grandmaster status at Starcraft 2}, 
    journal={British Broadcasting Corporation News}
}

@article{press_stylegan,
  title={How an AI ‘Cat-and-Mouse Game’Generates Believable Fake Photos},
  author={Metz, Cade and Collins, Keith},
  journal={The New York Times},
  year={2018}
}

@article{projection_net,
  title={Projectionnet: Learning efficient on-device deep networks using neural projections},
  author={Ravi, Sujith},
  journal={arXiv preprint arXiv:1708.00630},
  year={2017}
}

@article{random_project_high_d,
  title={Training neural networks on high-dimensional data using random projection},
  author={W{\'o}jcik, Piotr Iwo and Kurdziel, Marcin},
  journal={Pattern Analysis and Applications},
  volume={22},
  number={3},
  pages={1221--1231},
  year={2019},
  publisher={Springer}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inbook{ridge_lasso,
  title={The Lasso for Linear Models},
  booktitle={Statistical learning with sparsity: the lasso and generalizations},
  author={Hastie, Trevor and Tibshirani, Robert and Wainwright, Martin},
  year={2015},
  chapter={2},
  pages={7-24},
  publisher={Chapman and Hall/CRC}
}

@inproceedings{r-nns,
  title={Rich feature hierarchies for accurate object detection and semantic segmentation},
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={580--587},
  year={2014}
}

@article{rosenblatt ,
author = {Leon A. Gatys and David Eftekhary and Frank G House},
title = {A Neural Algorithm of Artistic Style},
journal = {Journal of Sketchy Physics},
volume = {13},
year = {2003},
number = {2},
pages = {46--129}
}

@inproceedings{stylegan,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4401--4410},
  year={2019}
}

@INPROCEEDINGS{svm,
    title = {A Training Algorithm for Optimal Margin Classifiers},
    author = {Bernhard E. Boser and Isabelle M. Guyon and Vladimir N. Vapnik},
    booktitle = {Proceedings of the 5th Annual ACM Workshop on Computational Learning Theory},
    year = {1992},
    pages = {144--152},
    publisher = {ACM Press}
}

@InProceedings{tale_dl,
  author     = {Jules, Damji and Brooke, Wenig},
  title      = {A Tale of Three Deep Learning Frameworks: TensorFlow, Keras and Deep Learning Pipelines},
  year       = {2018},
  eventtitle = {Spark+AI Summit 2018},
  eventdate  = {2018-06-04/2018-06-06},
  venue      = {San Francisco, United States of America},
}

@article{two_cultures,
  title={Statistical modeling: The two cultures (with comments and a rejoinder by the author)},
  author={Breiman, Leo and others},
  journal={Statistical science},
  volume={16},
  number={3},
  pages={199--231},
  year={2001},
  publisher={Institute of Mathematical Statistics}
}

@article{uap_mlp,
  title={Multilayer feedforward networks with a nonpolynomial activation function can approximate any function},
  author={Leshno, Moshe and Lin, Vladimir Ya and Pinkus, Allan and Schocken, Shimon},
  journal={Neural networks},
  volume={6},
  number={6},
  pages={861--867},
  year={1993},
  publisher={Elsevier}
}

@misc{uci_ml_data,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@article{unreasonable_dl,
	author = {Sejnowski, Terrence J.},
	title = {The unreasonable effectiveness of deep learning in artificial intelligence},
	elocation-id = {201907373},
	year = {2020},
	doi = {10.1073/pnas.1907373117},
	publisher = {National Academy of Sciences},
	abstract = {Deep learning networks have been trained to recognize speech, caption photographs, and translate text between languages at high levels of performance. Although applications of deep learning networks to real-world problems have become ubiquitous, our understanding of why they are so effective is lacking. These empirical results should not be possible according to sample complexity in statistics and nonconvex optimization theory. However, paradoxes in the training and effectiveness of deep learning networks are being investigated and insights are being found in the geometry of high-dimensional spaces. A mathematical theory of deep learning would illuminate how they function, allow us to assess the strengths and weaknesses of different network architectures, and lead to major improvements. Deep learning has provided natural ways for humans to communicate with digital devices and is foundational for building artificial general intelligence. Deep learning was inspired by the architecture of the cerebral cortex and insights into autonomy and general intelligence may be found in other brain regions that are essential for planning and survival, but major breakthroughs will be needed to achieve these goals.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/early/2020/01/23/1907373117},
	eprint = {https://www.pnas.org/content/early/2020/01/23/1907373117.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}

@inproceedings{yolo,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={779--788},
  year={2016}
}