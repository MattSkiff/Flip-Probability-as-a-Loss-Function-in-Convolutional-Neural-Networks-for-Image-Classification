\section{Discussion}

It is feasible to implement \gls{fp} in a way that resembles the cosine loss, although this comes at the expense of increased computation burden and poorer training accuracies. Implementing \gls{fp} in a way that allows for \gls{gd} has still not been done.
\bigskip

Other work leveraging \gls{rp}s exists. For example, \gls{rp}s have been used in projection networks in tandem with the full \gls{nn} to efficiently compress down (reduce the number of parameters of) the full networks to lessen the memory footprint. This allows projection networks to run on devices that have resource constraints, such as smartwatches \cite{projection_net}. 
\bigskip

\section{Limitations}