\chapter{Conclusion}

In conclusion, this dissertation presents a series of experiments around the use of \gls{fp} as loss function in a \gls{cnn}, as well as some background around the history of \gls{nn} and types of methods that might be used to implement them in a modern context. After these experiments we can conclude this particular implementation of \gls{fp}, though functional, is unable able to offer (by itself) any significant advantages over pre-existing methods. However, in the context of warm starting neural networks, some of the results had some promise. It is possible \gls{fp} could have some utility. Shaping this research further could require significant resources and remains for future work.